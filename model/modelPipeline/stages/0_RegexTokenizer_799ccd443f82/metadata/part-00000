{"class":"org.apache.spark.ml.feature.RegexTokenizer","timestamp":1719829907095,"sparkVersion":"3.5.0","uid":"RegexTokenizer_799ccd443f82","paramMap":{"pattern":"\\W","inputCol":"text","outputCol":"words"},"defaultParamMap":{"pattern":"\\s+","minTokenLength":1,"gaps":true,"toLowercase":true,"outputCol":"RegexTokenizer_799ccd443f82__output"}}
